<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>Yoneda Lemma & Photogrammetry: An Interactive Exploration</title>
<!-- Import Three.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r146/three.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/three@0.146/examples/js/controls/OrbitControls.js"></script>
<style>
  body {
    margin: 0;
    font-family: sans-serif;
    background: #f9f9fb;
    line-height: 1.6;
    color: #333;
  }
  h1, h2, h3 {
    color: #34568B;
  }
  h1 {
    margin-top: 1rem;
    text-align: center;
  }
  main {
    max-width: 1000px;
    margin: auto;
    padding: 1rem;
  }
  section {
    margin-bottom: 2rem;
  }
  .side-by-side {
    display: flex;
    flex-wrap: wrap;
    align-items: flex-start;
    gap: 1rem;
  }
  .text {
    flex: 1 1 300px;
  }
  .vis {
    flex: 1 1 300px;
    position: relative;
  }
  #threeContainer {
    width: 100%;
    height: 500px;
    border: 1px solid #ddd;
    background: white;
  }
  #controls {
    margin-top: 0.5rem;
    display: flex;
    gap: 0.5rem;
  }
  button {
    padding: 0.5rem 1rem;
    background: #34568B;
    color: white;
    border: none;
    border-radius: 4px;
    cursor: pointer;
  }
  button:hover {
    background: #2a4373;
  }
  #infoBox {
    margin-top: 1rem;
    padding: 1rem;
    background: #fffdf9;
    border-left: 5px solid #34568B;
    box-shadow: 0 2px 4px rgba(0,0,0,0.1);
  }
  canvas { display: block; }
</style>
</head>
<body>
<h1>Yoneda Lemma & Photogrammetry</h1>
<main>
  <section>
    <h2>1. The Yoneda Lemma</h2>
    <p>
      The Yoneda lemma is a cornerstone of category theory. It states that for a locally small category \(C\), a functor \(F: C \to \textbf{Set}\), and an object \(c\) in \(C\), there is a natural bijection between the set of natural transformations from the representable functor \(C(c, -)\) to \(F\) and the elements of \(F(c)\)【607663452290599†L4120-L4125】. In other words, an object \(X\) is completely determined by the collection of morphisms into it; its “splash patterns” encode all of its structure.
    </p>
    <p>
      To build intuition, imagine a mysterious object \(X\) in a dark room. You cannot see \(X\) directly, but you can send <em>probes</em> — simple shapes like points or lines — and record how they map into \(X\). The Yoneda lemma tells us that by knowing how every probe maps into \(X\), we can reconstruct \(X\) up to isomorphism. This conceptual shift—from objects to their interactions—fosters a powerful way of thinking about mathematics.
    </p>
  </section>

  <section>
    <h2>2. Photogrammetry: Reconstructing Objects from Views</h2>
    <p>
      Photogrammetry is the art of reconstructing a 3D object from many 2D photographs. A camera captures a <em>projection</em> of the scene onto a 2D image sensor. Each photograph records how light rays from the object map onto the flat image plane. By stitching together enough projections taken from different viewpoints, we can reconstruct the original shape. In this sense, the plenoptic function—the set of all possible rays—is the scene【607663452290599†L4120-L4125】.
    </p>
    <p>
      The analogy with the Yoneda lemma becomes clear: the camera plays the role of the probe \(A\), the image is the set of morphisms \(\text{Hom}(A, X)\), and the reconstruction is the colimit of these projections. The camera’s image plane is like a <em>tangent plane</em> to the hidden object, capturing local linear data. The key insight is that enough such local views, properly glued together, determine the global object.
    </p>
  </section>

  <section>
    <h2>3. Interactive: The Yoneda Splatting Engine</h2>
    <div class="side-by-side">
      <div class="vis">
        <div id="threeContainer"></div>
        <div id="controls">
          <button id="captureBtn">Capture View</button>
          <button id="resetBtn">Reset</button>
        </div>
      </div>
      <div class="text">
        <p id="infoBox">
          This interactive simulation demonstrates how the Yoneda lemma manifests in photogrammetry. An invisible torus knot \(X\) sits in the center of the scene. You control the camera—our probe—by rotating the view. Press <strong>Capture View</strong> to collect a “splat” of Gaussian points projected back into the volume along the current rays. Each splat corresponds to a 2D projection (an element of \(\text{Hom}(A, X)\)) being used to reconstruct \(X\). As you capture from different angles, the accumulation of splats reveals the hidden object, illustrating the Yoneda philosophy that an object is determined by its morphisms.
        </p>
      </div>
    </div>
  </section>
</main>

<script>
// Three.js setup for Yoneda Splatting Engine
(function(){
  const container = document.getElementById('threeContainer');
  const scene = new THREE.Scene();
  scene.background = new THREE.Color(0xf9f9fb);
  const camera = new THREE.PerspectiveCamera(45, container.clientWidth / container.clientHeight, 0.1, 1000);
  camera.position.set(0, 0, 6);

  const renderer = new THREE.WebGLRenderer({ antialias: true });
  renderer.setSize(container.clientWidth, container.clientHeight);
  container.appendChild(renderer.domElement);

  const controls = new THREE.OrbitControls(camera, renderer.domElement);
  controls.enableDamping = true;

  // Hidden object: Torus Knot
  const knotGeometry = new THREE.TorusKnotGeometry(1.0, 0.4, 200, 32);
  const knotMaterial = new THREE.MeshPhongMaterial({ color: 0x9a8c98, transparent: true, opacity: 0.1, side: THREE.DoubleSide });
  const knot = new THREE.Mesh(knotGeometry, knotMaterial);
  scene.add(knot);

  // Lights
  const ambient = new THREE.AmbientLight(0xffffff, 0.6);
  scene.add(ambient);
  const pointLight = new THREE.PointLight(0xffffff, 0.8);
  pointLight.position.set(5, 5, 5);
  scene.add(pointLight);

  // Splats: Points representing captured projections
  let splatGeometry = new THREE.BufferGeometry();
  let splatPositions = [];
  let splatColors = [];
  let splatMaterial = new THREE.PointsMaterial({ size: 0.05, vertexColors: true });
  let splatPoints = new THREE.Points(splatGeometry, splatMaterial);
  scene.add(splatPoints);

  function captureView() {
    // Sample a subset of vertices on the knot that are in front of the camera
    const positions = knotGeometry.attributes.position;
    const worldPosition = new THREE.Vector3();
    const localPosition = new THREE.Vector3();
    const matrixWorld = knot.matrixWorld;
    const cameraDir = new THREE.Vector3();
    camera.getWorldDirection(cameraDir);

    const color = new THREE.Color(Math.random(), Math.random(), Math.random());

    for (let i = 0; i < positions.count; i += 5) {
      localPosition.fromBufferAttribute(positions, i);
      worldPosition.copy(localPosition).applyMatrix4(matrixWorld);
      // Vector from camera to point
      const vectorToPoint = new THREE.Vector3().subVectors(worldPosition, camera.position);
      // Check if point is roughly in front of the camera (angle < 90°)
      if (vectorToPoint.dot(cameraDir) > 0) {
        // jitter point along ray to simulate splat thickness
        const jitter = worldPosition.clone().add(cameraDir.clone().multiplyScalar(0.02 * Math.random()));
        splatPositions.push(jitter.x, jitter.y, jitter.z);
        splatColors.push(color.r, color.g, color.b);
      }
    }
    updateSplats();
  }

  function updateSplats() {
    splatGeometry.dispose();
    splatGeometry = new THREE.BufferGeometry();
    const positionAttr = new THREE.Float32BufferAttribute(splatPositions, 3);
    const colorAttr = new THREE.Float32BufferAttribute(splatColors, 3);
    splatGeometry.setAttribute('position', positionAttr);
    splatGeometry.setAttribute('color', colorAttr);
    scene.remove(splatPoints);
    splatPoints = new THREE.Points(splatGeometry, splatMaterial);
    scene.add(splatPoints);
  }

  function resetSplats() {
    splatPositions = [];
    splatColors = [];
    updateSplats();
  }

  document.getElementById('captureBtn').addEventListener('click', captureView);
  document.getElementById('resetBtn').addEventListener('click', resetSplats);

  // Render loop
  function animate() {
    requestAnimationFrame(animate);
    controls.update();
    renderer.render(scene, camera);
  }
  animate();

  // Responsive
  window.addEventListener('resize', function() {
    const width = container.clientWidth;
    const height = container.clientHeight;
    camera.aspect = width / height;
    camera.updateProjectionMatrix();
    renderer.setSize(width, height);
  });
})();
</script>
</body>
</html>
